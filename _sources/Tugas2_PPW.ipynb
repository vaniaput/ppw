{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Crawling**\n",
        "\n",
        "Crawling adalah proses otomatis untuk mengambil data dari internet. Jika biasanya kita mencari dan menyalin informasi manual, crawling membuat komputer melakukannya sendiri, misalnya mengumpulkan judul, abstrak, dan link jurnal dari Springer secara cepat dan terstruktur."
      ],
      "metadata": {
        "id": "dsACuDcCX37V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpzfVfbfH4ZZ",
        "outputId": "8be2def3-9e77-48e6-92d0-e1a2e32951c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sprynger in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sprynger) (5.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from sprynger) (2.32.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from sprynger) (2.5.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from sprynger) (4.3.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->sprynger) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->sprynger) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->sprynger) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "pip install sprynger"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini digunakan untuk menambahkan pustaka sprynger ke Python, yang mempermudah akses ke Springer API untuk mencari dan mengambil data jurnal secara cepat dan terstruktur."
      ],
      "metadata": {
        "id": "wokon78taJYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Library**\n"
      ],
      "metadata": {
        "id": "xZ5OAGz0bf6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Mc-YzqSXaneW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini mengimpor dua pustaka penting. Requests digunakan untuk mengambil data dari internet atau API dengan mudah.Sementara itu, pandas berfungsi untuk mengolah data dalam bentuk tabel (DataFrame), sehingga informasi yang diambil dapat disusun rapi, dianalisis, atau disimpan dalam format seperti CSV. Kombinasi keduanya memungkinkan proses pengambilan sekaligus pengelolaan data berjalan lebih efisien."
      ],
      "metadata": {
        "id": "Huos_0rncEbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Menyiapkan API Key dan URL API**"
      ],
      "metadata": {
        "id": "n4sKF5DachHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"6bcc13d850fe0788fc38b6433765777c\"\n",
        "url = \"https://api.springernature.com/meta/v2/json\""
      ],
      "metadata": {
        "id": "AoxiReoUaryq"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini digunakan untuk menyimpan informasi penting agar program dapat mengakses Springer API. Variabel api_key menyimpan kunci autentikasi yang berfungsi seperti password agar permintaan kita dikenali dan diizinkan oleh Springer, sedangkan url menyimpan alamat endpoint API yang menyediakan data artikel dalam format JSON."
      ],
      "metadata": {
        "id": "yZ-512XwcX3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Menentukan Kata Kunci Pencarian**"
      ],
      "metadata": {
        "id": "lZJ1tV9hdTZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = [\"web mining\", \"web usage mining\", \"information retrieval\"]"
      ],
      "metadata": {
        "id": "IGeJFvd4autu"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya kode di atas berfungsi untuk mencari artikel di API Springer, yaitu ***Web mining, web usage mining, dan information retrival***"
      ],
      "metadata": {
        "id": "YThlFWw6eVq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Menyediakan wadah untuk menyimpan hasil**"
      ],
      "metadata": {
        "id": "rBkGtW0zdaOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_results = []"
      ],
      "metadata": {
        "id": "8u0q2B34a0dJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini berfungsi sebagai wadah penyimpanan sementara untuk menampung semua data artikel yang berhasil diambil dari API sebelum akhirnya disimpan ke file CSV"
      ],
      "metadata": {
        "id": "iK4j4buceuz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Proses crawling untuk setiap kata kunci**"
      ],
      "metadata": {
        "id": "sbgDnwOndmSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for keyword in keywords:\n",
        "    params = {\n",
        "        \"q\": keyword,\n",
        "        \"api_key\": api_key,\n",
        "        \"p\": 20\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)"
      ],
      "metadata": {
        "id": "bhTnVJRda4Y2"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disini saya melakukan proses crawling yang berfungsi untuk melakukan pencarian data artikel dari API Springer berdasarkan daftar kata kunci. Setiap kata kunci dimasukkan ke dalam parameter pencarian bersama API key dan jumlah hasil yang ingin ditampilkan (p=20), lalu dikirim menggunakan requests.get ke URL API Springer. Dengan cara ini, program dapat mengambil data artikel yang relevan sesuai kata kunci yang sedang diproses."
      ],
      "metadata": {
        "id": "AMrc7yFGfN3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mengecek apakah request berhasil**"
      ],
      "metadata": {
        "id": "8a7ERahkdtQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    total = data['result'][0]['total']\n",
        "    print(f\"Kata kunci '{keyword}' menghasilkan {total} hasil (ditampilkan sebagian).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMgOdKdSa_MR",
        "outputId": "1070be97-4fa4-4881-beee-ef6bc28fba76"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kata kunci 'information retrieval' menghasilkan 957626 hasil (ditampilkan sebagian).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini berguuna untuk memastikan apakah permintaan ke API berhasil. Jika **response.status_code == 200**, artinya permintaan sukses, lalu data hasil pencarian diubah menjadi format JSON dengan **response.json()**. Dari data tersebut, diambil informasi total jumlah hasil pencarian untuk kata kunci tertentu **(data['result'][0]['total'])**, kemudian ditampilkan di layar dengan pesan berapa banyak hasil yang ditemukan."
      ],
      "metadata": {
        "id": "rlPb2TspfiMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Menyimpan data penting dari hasil pencarian**"
      ],
      "metadata": {
        "id": "gqIRax9yd4g5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for record in data['records']:\n",
        "    all_results.append({\n",
        "        \"keyword\": keyword,\n",
        "        \"doi\": record.get('doi', 'N/A'),\n",
        "        \"title\": record.get('title', 'No title'),\n",
        "        \"publicationName\": record.get('publicationName', 'Unknown'),\n",
        "        \"publicationDate\": record.get('publicationDate', 'Unknown'),\n",
        "        \"url\": record.get('url', [{}])[0].get('value', 'N/A'),\n",
        "        \"abstract\": record.get('abstract', 'No abstract')\n",
        "    })"
      ],
      "metadata": {
        "id": "iT-x-y_nbFK7"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini menyimpan tiap artikel dari data['records'] ke dalam all_results dengan informasi seperti keyword, DOI, judul, publikasi, tanggal, URL, dan abstrak, sambil memberi nilai default jika data tidak ada."
      ],
      "metadata": {
        "id": "2F3wIwtggFIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Menyimpan hasil ke file CSV**"
      ],
      "metadata": {
        "id": "IJQ2FVled86o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"springer_crawling.csv\"\n",
        "df = pd.DataFrame(all_results)\n",
        "df.to_csv(filename, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"✅ Data berhasil disimpan ke {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCcKsq0pbHF_",
        "outputId": "b85159f0-c344-4cae-e9aa-8466e6048737"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data berhasil disimpan ke springer_crawling.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini membuat nama file **springer_crawling.csv**, lalu mengubah kumpulan data all_results menjadi **DataFrame** dengan pandas. Setelah itu, data disimpan ke file CSV tanpa menuliskan index dan menggunakan encoding UTF-8. Terakhir, program mencetak pesan bahwa file berhasil dibuat."
      ],
      "metadata": {
        "id": "eP5weYuMgZvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mengunduh file CSV**"
      ],
      "metadata": {
        "id": "FRTb8A1xeA8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"springer_crawling.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WH4UJY2obLfh",
        "outputId": "1157ae84-df35-4342-f4bb-39d3e4e9b467"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3a1595fb-d158-442d-a19b-717088e0996a\", \"springer_crawling.csv\", 30990)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini digunakan di Google Colab untuk mengunduh file hasil penyimpanan. Baris pertama mengimpor modul **files** dari **google.colab**, lalu baris kedua memanggil fungsi files.download() agar file **springer_crawling.csv** yang sudah dibuat bisa langsung diunduh ke komputer pengguna."
      ],
      "metadata": {
        "id": "eiSFtpDggyqS"
      }
    }
  ]
}