{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031dedc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, string\n",
    "from bs4 import BeautifulSoup\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from spellchecker import SpellChecker\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup tqdm untuk apply pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Kamus slang\n",
    "contractions_dict = {\n",
    "    \"gak\": \"tidak\", \"ga\": \"tidak\", \"nggak\": \"tidak\", \"enggak\": \"tidak\", \"ngga\": \"tidak\", \"gk\": \"tidak\",\n",
    "    \"gue\": \"saya\", \"gw\": \"saya\", \"gua\": \"saya\", \"lu\": \"kamu\", \"loe\": \"kamu\",\n",
    "    \"dah\": \"sudah\", \"udah\": \"sudah\", \"aja\": \"saja\", \"yg\": \"yang\", \"utk\": \"untuk\",\n",
    "    \"tp\": \"tetapi\", \"tapi\": \"tetapi\", \"bgt\": \"sekali\", \"lg\": \"lagi\"\n",
    "}\n",
    "\n",
    "stop_words = set([\n",
    "    \"yang\",\"di\",\"ke\",\"dan\",\"dari\",\"ini\",\"itu\",\"pada\",\"untuk\",\n",
    "    \"dengan\",\"sebagai\",\"adalah\",\"merupakan\",\"dalam\",\"yaitu\",\n",
    "    \"suatu\",\"sebuah\",\"akan\",\"telah\",\"bisa\",\"agar\",\"oleh\",\n",
    "    \"bahwa\",\"juga\",\"atau\",\"tidak\",\"namun\",\"tetapi\",\"kemudian\"\n",
    "])\n",
    "\n",
    "# Stemmer dan SpellChecker\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "spell = SpellChecker()\n",
    "\n",
    "# --- Fungsi Preprocessing ---\n",
    "def clean_base_text(text):\n",
    "    if not isinstance(text, str): return ''\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    words = [contractions_dict.get(w, w) for w in words]\n",
    "    text = ' '.join(words)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    return text\n",
    "\n",
    "def tokenize(text): return text.split()\n",
    "def remove_stopwords(tokens): return [w for w in tokens if w not in stop_words]\n",
    "def stemming(tokens): return stemmer.stem(' '.join(tokens)).split()\n",
    "def correct(tokens): return [spell.correction(w) or w for w in tokens]\n",
    "\n",
    "# --- Main Preprocessing ---\n",
    "def preprocess():\n",
    "    print(\"ðŸ“‚ Membaca file CSV...\")\n",
    "    df = pd.read_csv(\"pta_manajemen_raw.csv\")\n",
    "    print(f\"âœ… Dataset terbaca, jumlah data: {len(df)} baris\\n\")\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 1: Cleaning...\")\n",
    "    df[\"abstrak_indonesia_clean\"] = df[\"abstrak_indonesia\"].progress_apply(clean_base_text)\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 2: Tokenizing...\")\n",
    "    df[\"abstrak_indonesia_tokens\"] = df[\"abstrak_indonesia_clean\"].progress_apply(tokenize)\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 3: Remove Stopwords...\")\n",
    "    df[\"abstrak_indonesia_stopwords\"] = df[\"abstrak_indonesia_tokens\"].progress_apply(remove_stopwords)\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 4: Stemming...\")\n",
    "    df[\"abstrak_indonesia_stemmed\"] = df[\"abstrak_indonesia_stopwords\"].progress_apply(stemming)\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 5: Spell Correction...\")\n",
    "    df[\"abstrak_indonesia_corrected\"] = df[\"abstrak_indonesia_stemmed\"].progress_apply(correct)\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 6: Hitung Frekuensi Kata...\")\n",
    "    df[\"frekuensi_kata_indonesia\"] = df[\"abstrak_indonesia_stemmed\"].progress_apply(lambda x: dict(Counter(x)))\n",
    "\n",
    "    print(\"\\nðŸ’¾ Menyimpan hasil preprocessing ke pta_manajemen_preprocessed.csv...\")\n",
    "    df.to_csv(\"pta_manajemen_preprocessed.csv\", index=False)\n",
    "    print(\"âœ… Preprocessing selesai.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19cefeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Membaca file CSV...\n",
      "âœ… Dataset terbaca, jumlah data: 1031 baris\n",
      "\n",
      "ðŸ”„ Tahap 1: Cleaning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [00:00<00:00, 3436.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Tahap 2: Tokenizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [00:00<00:00, 41933.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Tahap 3: Remove Stopwords...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [00:00<00:00, 45354.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Tahap 4: Stemming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [09:35<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Tahap 5: Spell Correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [9:05:44<00:00, 31.76s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Tahap 6: Hitung Frekuensi Kata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [00:00<00:00, 53527.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Menyimpan hasil preprocessing ke pta_manajemen_preprocessed.csv...\n",
      "âœ… Preprocessing selesai.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, string\n",
    "from bs4 import BeautifulSoup\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from spellchecker import SpellChecker\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup tqdm untuk apply pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Kamus slang\n",
    "contractions_dict = {\n",
    "    \"gak\": \"tidak\", \"ga\": \"tidak\", \"nggak\": \"tidak\", \"enggak\": \"tidak\", \"ngga\": \"tidak\", \"gk\": \"tidak\",\n",
    "    \"gue\": \"saya\", \"gw\": \"saya\", \"gua\": \"saya\", \"lu\": \"kamu\", \"loe\": \"kamu\",\n",
    "    \"dah\": \"sudah\", \"udah\": \"sudah\", \"aja\": \"saja\", \"yg\": \"yang\", \"utk\": \"untuk\",\n",
    "    \"tp\": \"tetapi\", \"tapi\": \"tetapi\", \"bgt\": \"sekali\", \"lg\": \"lagi\"\n",
    "}\n",
    "\n",
    "stop_words = set([\n",
    "    \"yang\",\"di\",\"ke\",\"dan\",\"dari\",\"ini\",\"itu\",\"pada\",\"untuk\",\n",
    "    \"dengan\",\"sebagai\",\"adalah\",\"merupakan\",\"dalam\",\"yaitu\",\n",
    "    \"suatu\",\"sebuah\",\"akan\",\"telah\",\"bisa\",\"agar\",\"oleh\",\n",
    "    \"bahwa\",\"juga\",\"atau\",\"tidak\",\"namun\",\"tetapi\",\"kemudian\"\n",
    "])\n",
    "\n",
    "# Stemmer dan SpellChecker\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "spell = SpellChecker()\n",
    "\n",
    "# --- Fungsi Preprocessing ---\n",
    "def clean_base_text(text):\n",
    "    if not isinstance(text, str): return ''\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    words = [contractions_dict.get(w, w) for w in words]\n",
    "    text = ' '.join(words)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    return text\n",
    "\n",
    "def tokenize(text): return text.split()\n",
    "def remove_stopwords(tokens): return [w for w in tokens if w not in stop_words]\n",
    "def stemming(tokens): return stemmer.stem(' '.join(tokens)).split()\n",
    "def correct(tokens): return [spell.correction(w) or w for w in tokens]\n",
    "\n",
    "# --- Main Preprocessing ---\n",
    "def preprocess():\n",
    "    print(\"ðŸ“‚ Membaca file CSV...\")\n",
    "    df = pd.read_csv(\"pta_manajemen_raw.csv\")\n",
    "    print(f\"âœ… Dataset terbaca, jumlah data: {len(df)} baris\\n\")\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 1: Cleaning...\")\n",
    "    df[\"abstrak_indonesia_clean\"] = df[\"abstrak_indonesia\"].progress_apply(clean_base_text)\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 2: Tokenizing...\")\n",
    "    df[\"abstrak_indonesia_tokens\"] = df[\"abstrak_indonesia_clean\"].progress_apply(tokenize)\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 3: Remove Stopwords...\")\n",
    "    df[\"abstrak_indonesia_stopwords\"] = df[\"abstrak_indonesia_tokens\"].progress_apply(remove_stopwords)\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 4: Stemming...\")\n",
    "    df[\"abstrak_indonesia_stemmed\"] = df[\"abstrak_indonesia_stopwords\"].progress_apply(stemming)\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 5: Spell Correction...\")\n",
    "    df[\"abstrak_indonesia_corrected\"] = df[\"abstrak_indonesia_stemmed\"].progress_apply(correct)\n",
    "\n",
    "    print(\"ðŸ”„ Tahap 6: Hitung Frekuensi Kata...\")\n",
    "    df[\"frekuensi_kata_indonesia\"] = df[\"abstrak_indonesia_stemmed\"].progress_apply(lambda x: dict(Counter(x)))\n",
    "\n",
    "    print(\"\\nðŸ’¾ Menyimpan hasil preprocessing ke pta_manajemen_preprocessed.csv...\")\n",
    "    df.to_csv(\"pta_manajemen_preprocessed.csv\", index=False)\n",
    "    print(\"âœ… Preprocessing selesai.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7bfaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
